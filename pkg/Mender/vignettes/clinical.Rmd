---
title: "Mender: A Clinical Data Set Example"
author: "Kevin R. Coombes and Jake Reed"
data: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Mender: A Clinical Data Set Example}
  %\VignetteKeywords{TDA, topologicla data analysis, c;inical data}
  %\VignetteDepends{Mender,igraph,Polychrome,Mercator,ClassDiscovery,dendextend,ape}
  %\VignettePackage{Mender}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r opts, echo=FALSE}
knitr::opts_chunk$set(fig.width=5, fig.height=5)
options(width=96)
.format <- knitr::opts_knit$get("rmarkdown.pandoc.to")
.tag <- function(N, cap ) ifelse(.format == "html",
                                 paste("Figure", N, ":",  cap),
                                 cap)
```
# Introduction
We want to illustrate the `Mender` package (Version `r packageVersion("Mender")`)
with a clinical data set. Not surprisingly, we start by loading the package.
```{r Mender}
library(Mender)
```
We also load several other useful packages (some of which may eventually get incorporated
into the package requirements).
```{r libpack}
suppressMessages( library(Mercator) )
library(ClassDiscovery)
library(Polychrome)
data(Dark24)
data(Light24)
suppressMessages( library(igraph) )
suppressMessages( library(dendextend) )
suppressMessages( library("ape") )
```
Now we fetch the sample clinical data set that is included with the package.
```{r CLL}
data(CLL)
ls()
dim(clinical)
colnames(clinical)
```
The `clinical` object is a numeric matrix containing the clinical data (binary values have
been converted to 0-1; categorical values to integers). The `daisydist` is a distance matrix
(stored as a `dist` object). Coombes and colleagues [J Biomed Inform. 2021 Jun;118:103788]
showed that this is the best way to measure distances between mixed-type clinical data. The
`ripdiag` object is a "Rips diagram" produced by applying the `TDA` algorithm to the daisy
distances.

# TDA Built-in Visualizations of the Rips Diagram
Here are some plots of the `TDA` results using tools from the original package.
(I am not sure what any of these are really good for.)
```{r fig01, fig.width = 9, fig.cap = .tag(1, "The Rips barcode diagram from TDA.")}
diag <- ripdiag[["diagram"]]
opar <- par(mfrow = c(1,2))
plot(diag, barcode = TRUE, main = "Barcode")
plot(diag, main = "Rips Diagram")
par(opar)
rm(opar)
```

```{r fig02, fig.width = 12, fig.cap = .tag(2, "Landscape, silhouette, and lambda-cluster plots of the Rips diagram, from TDA.")}
L <- TDA::landscape(diag, KK = 1)
S <- TDA::silhouette(diag)
crt <- TDA::clusterTree(as.matrix(daisydist), k = 5, dist = "arbitrary")

opar <- par(mfrow = c(1, 3))
plot(L, type = "l", main = "Landscape")
plot(S, type = "l", main = "Silhouette")
plot(crt, type = "lambda",main = "Lambda Cluster Tree")
par(opar)
rm(L, S, opar)
```


# Mercator Visualizations of the Underlying Data and Distance Matrix
Now we use our `Mercator` package to view the underlying data.
```{r merc}
mercury <- Mercator(daisydist, metric = "daisy", method = "hclust", K = 8)
mercury <- addVisualization(mercury, "mds")
mercury <- addVisualization(mercury, "tsne")
mercury <- addVisualization(mercury, "umap")
mercury <- addVisualization(mercury, "som")
```

```{r fig03, fig.width = 9, fig.height = 12, fig.cap = .tag(3, "Mercator Visualizations of the distance matrix.")}
opar <- par(mfrow = c(3,2), cex = 1.1)
plot(mercury, view = "hclust")
plot(mercury, view = "mds", main = "Mult-Dimensional Scaling")
plot(mercury, view = "tsne", main = "t-SNE")
plot(mercury, view = "umap", main = "UMAP")
barplot(mercury, main = "Silhouette Width")
plot(mercury, view = "som", main = "Self-Organizing Maps")
par(opar)
rm(opar)
```

# Dimension Zero
Here is a picture of the "zero-cycle" data, which can also be used ultimately to cluster
the points (where each point is a patient). The connected lines are similar to a
single-linkage clustering structure, showing when individual points are merged together
as the TDA parameter increases.
```{r fig04, fig.cap = .tag(4, "Hierarchical connections between zero cycles.")}
nzero <- sum(diag[, "dimension"] == 0)
cycles <- ripdiag[["cycleLocation"]][2:nzero]
W <- mercury@view[["umap"]]$layout
plot(W, main = "Connected Zero Cycles")
for (cyc in cycles) {
  points(W[cyc[1], , drop = FALSE], pch = 16,col = "red")
  X <- c(W[cyc[1], 1], W[cyc[2],1])
  Y <- c(W[cyc[1], 2], W[cyc[2],2])
  lines(X, Y)
}
```

# Using iGraph
We can convert the 0-dimensional cycle structure into a dendrogram, by first passing them
through the `igraph` package. We start by putting all the zero-cycle data together, which
can be viewed as an "edge-list" from the `igraph` perspective.
```{r igraph}
edges <- t(do.call(cbind, cycles)) # this creates an "edgelist"
G <- graph_from_edgelist(edges)
G <- set_vertex_attr(G, "label", value = attr(daisydist, "Labels"))
```
Note that we attached the sample names to the graph, obtaining them from the daisy
distance matrix. Now we use two different algorithms to decide how to layout the graph.
```{r layouts}
set.seed(2734)
Lt <- layout_as_tree(G)
L <- layout_with_fr(G)
```

```{r fig05, fig.cap = .tag(5, "Two igraph depictions of the zero cycle structure."), fig.width = 10}
opar <- par(mfrow = c(1,2), mai = c(0.01, 0.01, 1.02, 0.01))
plot(G, layout = Lt, main = "As Tree")
plot(G, layout = L, main = "Fruchterman-Reingold")
par(opar)
```
Note that the Fruchterman-Reingold layout gives the most informative structure.

## Community Structure
There are a variety of community-finding algorithms that we can apply. (Communities
in grpah theory are similar to clusters in other machine learning areas of study.)
"Edge-betweenness" seems  to work best.
```{r keg}
# #keg <- cluster_fluid_communities(G, 12) # 12, as requested, though with comlpaints
#keg <- cluster_leading_eigen(G)    # undirected
#keg <- cluster_fast_greedy(G)      # undirected
#keg <- cluster_louvain(G)          # undirected
#keg <- cluster_leiden(G)           # undirected
#keg <- cluster_optimal(G)          # too slow
# keg <- cluster_label_prop(G)       # 177 (terrible!)
# keg <- cluster_infomap(G)          # 34
# keg <- cluster_walktrap(G)         # 24
# keg <- cluster_spinglass(G)        # 21
keg <- cluster_edge_betweenness(G) # 20
table(membership(keg)) 
pal <- Dark24[membership(keg)]
```

The first line in the next code chunk shows that we did actually produce a tree.
We explore three different ways ro visualize it
```{r fig06, fig.width = 6, fig.height = 6, fig.cap = .tag(6, "Community structure, simplified.")}
is.hierarchical(keg)
H <- as.hclust(keg)
H$labels <- attr(daisydist, "Labels")
K <-  7
colset <- Light24[cutree(H, k=K)]
G2 <- set_vertex_attr(G, "color", value = colset)
e <- 0.01
opar <- par(mai = c(e, e, e, e))
plot(G2, layout = L)
par(opar)
```

```{r fig07, fig.width = 8, fig.cap = .tag(7, "Dendrogram realization, using the dendextend package.")}
D <- as.dendrogram(H)
labels_colors(D) <- colset[order.dendrogram(D)]
plot(D, main = "Dendextend/Dendrogram")
```

```{r fig08, fig.width=7, fig.height = 7, fig.cap = .tag(8, "Cladogram realization, from the ape package.")}
P <- as.phylo(H)
opar <- par(mai = c(0.01, 0.01, 1.0, 0.01))
plot(P, type = "u", tip.color = colset, cex = 0.8, main = "Ape/Cladogram")
par(opar)
rm(opar)
```


We can visualize the `r K` clusters on the original data.
```{r fig09, fig.width=10, fig.height = 10, fig.cap = .tag(9, "Mercator visualizations of TDA-iGraph clusters.")}
K = 7
venus <- recluster(mercury, K = K)
newc <- cutree(H, k = K)
names(newc) <- attr(venus@distance,"Labels")
venus <- setClusters(venus, newc)
venus@palette <- Light24

swap <- invertColors()
opar <- par(mfrow = c(2,2), cex = 1.2)
plot(venus, view = "hclust")
plot(venus, view = "mds", main = "MDS")
plot(venus, view = "tsne", main = "t-SNE")
plot(venus, view = "umap", main = "UMAP")
par(opar)
par(swap)
```

## Visualizing Features
In any of the "scatter plot views" (e.g., MDS, UMAP, t-SNE) from Mercator, we may want to overlay different colors to repesent differnt clinical features
```{r views}
U <- mercury@view[["mds"]]
V <- mercury@view[["tsne"]]$Y
W <- mercury@view[["umap"]]$layout
```

```{r fig10, fig.width = 9, fig.cap = .tag(10, "UMAP visualizations with clinical features.")}
featSex <- Feature(clinical[,"Sex"], "Sex", c("pink", "skyblue"), c("Female", "Male"))
featRai <- Feature(clinical[,"CatRAI"], "Fai Stage", c("green", "magenta"), c("High", "Low"))
opar <- par(mfrow = c(1,2))
plot(W, main = "UMAP; Sex", xlab = "U1", ylab = "U2")
points(featSex, W, pch = 16, cex = 1.4)
plot(W, main = "UMAP; Rai Stage", xlab = "U1", ylab = "U2")
points(featRai, W, pch = 16, cex = 1.4)
par(opar)
rm(opar)
```

# Significance
We have a statistical approach to deciding which of the detected cycles are statistically
significant. Empirically, the persistence of 0-dimensional cycles looks like a gamma
distribution, while the persistence of higher dimensional cycles looks like an exponential
distribution. In both cases, we use an empirical Bayes approach, treating the observed
distribution as a mixture of either gamma or exponential (as appropriate) with an unknown
distribution contributing to heavier tails.
```{r persistence}
persistence <- diag[, "Death"] - diag[, "Birth"]
```

## Zero-Cycles (Connected Components)
```{r d0}
d0 <- persistence[diag[, "dimension"] == 0]
d0 <- d0[d0 < 1]
summary(d0)
mu <- mean(d0)
nu <- median(d0)
sigma <- sd(d0)
shape <- mu^2/sigma^2
rate <- mu/sigma^2
xx <- seq(0, 0.23, length = 100)
yy <- dgamma(xx, shape = shape, rate = rate)
hist(d0, breaks = 123, freq = FALSE)
lines(xx, yy, col = "purple", lwd = 2)
```

## One-Cycles (Loops)
Now we want to determine if there are significant "loops" in the data, and, if so,
how many?
```{r d1}
d1 <- persistence[diag[, "dimension"] == 1]
ef <- ExpoFit(d1) # should be close to log(2)/median? 
plot(ef)
eb <- EBexpo(d1, 200)
hist(eb)
plot(eb, prior = 0.56)
sum(d1 > cutoff(0.8, 0.56, eb)) # posterior 80%, prior 0.56
sum(d1 > 0.065) # post 90%
which(d1 > 0.047)
which(d1 > 0.065)
```

Let's pick out the most persistent 1-cycle.
```{r}
cyc1 <- Cycle(ripdiag, 1, 236, "forestgreen")
cyc1@index
```

Each row represents an edge, by listing the IDs of the points at either end of
the line segment. In this case, there are nine edges that link together to form
a connect loop (or topological circle). 

```{r fig.width = 12}
cyc2 <- Cycle(ripdiag, 1, 123, "red")
cyc3 <- Cycle(ripdiag, 1, 214, "purple")

opar <- par(mfrow = c(1, 3))
plot(cyc1, W, lwd = 2, pch = 16, col = "gray", xlab = "U1", ylab = "U2", main = "UMAP")
lines(cyc2, W, lwd=2)
lines(cyc3, W, lwd=2)

plot(U, pch = 16, col = "gray", main = "MDS")
lines(cyc1, U, lwd = 2)
lines(cyc2, U, lwd = 2)
lines(cyc3, U, lwd = 2)

plot(V, pch = 16, col = "gray", main = "t-SNE")
lines(cyc1, V, lwd = 2)
lines(cyc2, V, lwd = 2)
lines(cyc3, V, lwd = 2)
par(opar)
rm(opar)
```

```{r recycle, eval = FALSE}
poof <- Mender:::angleMean(W, ripdiag, cyc1@index)
```

## Two-Cycles (Voids)
Now we want to determine if there are significant "voids" (empty interiors of spheres) in
the data, and, if so, how many?
```{r d2}
d2 <- persistence[diag[, "dimension"] == 2]
ef <- ExpoFit(d2) # should be close to log(2)/median? 
plot(ef)
eb <- EBexpo(d2, 200)
hist(eb)
plot(eb, prior = 0.75)
sum(d2 > cutoff(0.8, 0.75, eb)) # posterior 80%, prior 0.56
sum(d2 > cutoff(0.95, 0.75, eb)) # posterior 90%, prior 0.56
cutoff(0.95, 0.75, eb)
sum(d2 > 0.032) # post 90%
which(d2 > 0.032)
```

```{r}
vd <- getCycle(ripdiag, 2)
mds <- cmdscale(daisydist, k = 3)
support <- cycleSupport(vd, mds)
```